{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Face Recognition Experiments, Take 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This notebook documents my attempts at building a convolutional neural network (CNN) to recognize a human face within an image. With this set of experiments, I take the illogical clue that less is more and build an experiment which increasingly adds images to both the positive and then the negative cases.  I'll take the data set from Experiment 3 from Take 1.\n",
    "\n",
    "Experiment 1: Used 919 human faces, 468 dog faces and 334 non-face pictures.   This experiment erroneously combined human and dog faces since I thought it was supposed to just identify faces, of whatever species.  The result was a network that had over 80% accuracy.  These images where divided into two categories: Yes (there is a face in the picture) and No (there is no face in the picture).  Additionally, I limited the number of faces to 2 per picture and deleted any that had features that I thought might confuse the network, like distortions or strange makeup.\n",
    "\n",
    "Experiment 2: Thinking that more data would make a better network, I removed the dog faces and increased the number of positive category images to around 2202.  My criteria was a bit more loose in that faces with painting were included. I reasoned that if I could identify it as a face, so should the network.  Likewise, I increased the negative category images to  1384.  Finally, since the initial performance was much worse, I used an Keras' Image Generator to provide more variety.  It didn't help much. Overall, the accuracy decrease by about 16% with the additional images.\n",
    "\n",
    "Experiment 3: Since the final network needs to distinguish between canine and human faces, I added the 468 dog faces to the negative category. This resulted in an additional decrease of around 7% in accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load Libraries\n",
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Dense, Activation, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import optimizers\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Define Functions\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 2)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "def load_data(path, pct_images=1):\n",
    "    global train_files, train_targets, train_tensors\n",
    "    global valid_files, valid_targets, valid_tensors\n",
    "    global test_files, test_targets, test_tensors\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    all_files, all_targets = load_dataset(path)\n",
    "\n",
    "    if pct_images > 1:\n",
    "            pct_images = 1\n",
    "    all_cnt = int(len(all_files))  # Reduce image library\n",
    "    \n",
    "    train_idx = int(0.5 * all_cnt*pct_images)\n",
    "    valid_idx = int(0.3 * all_cnt + train_idx)\n",
    "    test_idx = int(0.2 * all_cnt + valid_idx)\n",
    "\n",
    "    shuffled = np.random.choice(all_cnt,all_cnt).astype(int)\n",
    "    \n",
    "    train_files   = all_files[shuffled[:train_idx]]\n",
    "    train_targets = all_targets[shuffled[:train_idx]]\n",
    "\n",
    "    valid_files   = all_files[shuffled[train_idx:valid_idx]]\n",
    "    valid_targets = all_targets[shuffled[train_idx:valid_idx]]\n",
    "\n",
    "    test_files   = all_files[shuffled[valid_idx:test_idx+1]]\n",
    "    test_targets = all_targets[shuffled[valid_idx:test_idx+1]]\n",
    "    \n",
    "    all_yes = np.sum(all_targets[:,1])\n",
    "    all_no = np.sum(all_targets[:,0])\n",
    "    print('Library Ratio:')\n",
    "    print('  Yes: {0}/{1} or {2:0.4f}'.format(all_yes,all_cnt, all_yes/all_cnt))\n",
    "    print('   No: {0}/{1} or {2:0.4f}'.format(all_no,all_cnt, all_no/all_cnt))\n",
    "    train_yes = np.sum(train_targets[:,1])\n",
    "    train_no = np.sum(train_targets[:,0])\n",
    "    print('Train Ratio:')\n",
    "    print('  Yes: {0}/{1} or {2:0.4f}'.format(train_yes,train_idx, train_yes/train_idx))\n",
    "    print('   No: {0}/{1} or {2:0.4f}'.format(train_no,train_idx, train_no/train_idx))\n",
    "    \n",
    "    for i in range(len(valid_files)):\n",
    "        #print(valid_files[i][8:10],valid_targets[i])\n",
    "        if (\n",
    "                (valid_files[i][8:10]=='No') & (valid_targets[i][0]==0) |\n",
    "                (valid_files[i][8:11]=='Yes') & (valid_targets[i][0]==1)\n",
    "            ):\n",
    "            print(valid_files[i],valid_targets[i])\n",
    "\n",
    "    # pre-process the data for Keras\n",
    "    train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "    valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "    test_tensors = paths_to_tensor(test_files).astype('float32')/255\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Experiment 3, Take 2\n",
    "* Positive Category\n",
    ">* 2202 Human Faces\n",
    "\n",
    "* Negative Category\n",
    ">* 1384 Images with no faces\n",
    ">* 468 Dog Faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### A. Check Random Training Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### B. Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def build_train_network(epochs, batch_size, train_tensors, train_targets, valid_tensors, valid_targets):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(128, (5, 5), input_shape=(224, 224,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (5, 5)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(128, (5, 5)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64*2, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Conv2D(64*2, (3, 3)))\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(Dense(100))\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    opt = optimizers.RMSprop(lr=1e-5)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    #model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.find_faces.hdf5', \n",
    "                                   verbose=1, save_best_only=True)\n",
    "    early = EarlyStopping(monitor='val_acc', min_delta=0, patience=8, verbose=1, mode='auto')\n",
    "\n",
    "    ## Original fit call before using the ImageDataGenerator\n",
    "    #model.fit(train_tensors, train_targets, \n",
    "    #          validation_data=(valid_tensors, valid_targets),\n",
    "    #          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=2)\n",
    "\n",
    "    # this is the augmentation configuration I will use for training\n",
    "    train_datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True)\n",
    "\n",
    "    train_generator = train_datagen.flow(train_tensors, train_targets)\n",
    "    validation_generator = train_datagen.flow(valid_tensors, valid_targets)\n",
    "\n",
    "#    train_cnt = train_tensors.shape[0]\n",
    "#    valid_cnt = valid_tensors.shape[0]\n",
    "\n",
    "    model.fit_generator(\n",
    "            train_generator\n",
    "            , steps_per_epoch=2000 // batch_size\n",
    "            , epochs=epochs\n",
    "            , validation_data=validation_generator\n",
    "            , validation_steps=800 // batch_size\n",
    "            , callbacks=[checkpointer, early], verbose=2)\n",
    "\n",
    "    model.load_weights('saved_models/weights.best.find_faces.hdf5')\n",
    "\n",
    "    # get index of predicted dog breed for each image in test set\n",
    "    face_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "    # report test accuracy\n",
    "    test_accuracy = 100*np.sum(np.array(face_predictions)==np.argmax(test_targets, axis=1))/len(face_predictions)\n",
    "    print(train_tensors.shape[0],' Images with test accuracy of: %.4f%%' % test_accuracy)\n",
    "    print('*' * 80)\n",
    "    print('*' * 80)\n",
    "    print('')\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### I. C. Get Accuracy Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 200\n",
    "pct_range = np.array([.1, .25, .5, .75, 1])\n",
    "exp_range = np.array([1,2,3])\n",
    "test_acc = {}\n",
    "\n",
    "for exp in exp_range:\n",
    "    load_data('images\\Experiment_' + exp,pct)\n",
    "    for pct in pct_range:\n",
    "        print('>>>> Experiment ' + exp + ' Starting %.2f%%' % pct)\n",
    "        acc = build_train_network(epochs, batch_size, train_tensors, train_targets, valid_tensors, valid_targets)\n",
    "        old_acc = test_acc[exp-1]\n",
    "        old_acc.append(acc)\n",
    "        test_acc[exp-1] = old_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                   \n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [12.0, 10.0]\n",
    "#i = np.random.choice(len(train_tensors))\n",
    "#img = train_tensors[i]\n",
    "#print(train_targets[i])\n",
    "#plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.plot(pct_range, test_acc)\n",
    "plt.title('Test Accuracy by Percentage of Training Images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
