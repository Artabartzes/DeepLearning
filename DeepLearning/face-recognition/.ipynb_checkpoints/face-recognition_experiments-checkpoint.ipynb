{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook documents my attempts at building a convolutional neural network (CNN) to recognize a human face within an image.  I did this with three experiments using different images sets, each getting signficantly worse results.\n",
    "\n",
    "Experiment 1: Using 919 human faces, 468 dog faces and 334 non-face pictures.   This experiment erroneously combined human and dog faces since I thought it was supposed to just identify faces, of whatever species.  The result was a network that had over 80% accuracy.  These images where divided into two categories: Yes (there is a face in the picture) and No (there is no face in the picture).  Additionally, I limited the number of faces to 2 per picture and deleted any that had features that I thought might confuse the network, like distortions or strange makeup.\n",
    "\n",
    "Experiment 2: Thinking that more data would make a better network, I removed the dog faces and increased the number of positive category images to around 2202.  My criteria was a bit more loose in that faces with painting were included. I reasoned that if I could identify it as a face, so should the network.  Likewise, I increased the negative category images to  1384.  Finally, since the initial performance was much worse, I used an Keras' Image Generator to provide more variety.  It didn't help much. Overall, the accuracy decrease by about 20% with the additional images.\n",
    "\n",
    "Experiment 3: Since the final network needs to distinguish between canine and human faces, I added the 468 dog faces to the negative category. This resulted in an additional decrease of around 5% in accuracy.\n",
    "\n",
    "This is overall quite illogical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1\n",
    "* Positive Category\n",
    ">* 919 Human Faces\n",
    ">* 468 Dog Faces\n",
    "\n",
    "* Negative Category\n",
    ">* 334 Images with no faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define Functions\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 2)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "def load_data(path):\n",
    "    global train_files, train_targets, train_tensors\n",
    "    global valid_files, valid_targets, valid_tensors\n",
    "    global test_files, test_targets, test_tensors\n",
    "\n",
    "    all_files, all_targets = load_dataset(path)\n",
    "\n",
    "    all_cnt = int(len(all_files)/2)\n",
    "    train_idx = int(0.5 * all_cnt)\n",
    "    valid_idx = int(0.3 * all_cnt + train_idx)\n",
    "    test_idx = int(0.2 * all_cnt + valid_idx)\n",
    "\n",
    "    np.random.seed(42)\n",
    "    shuffled = np.random.choice(all_cnt,all_cnt).astype(int)\n",
    "    train_files   = all_files[shuffled[:train_idx]]\n",
    "    train_targets = all_targets[shuffled[:train_idx]]\n",
    "\n",
    "    valid_files   = all_files[shuffled[train_idx:valid_idx]]\n",
    "    valid_targets = all_targets[shuffled[train_idx:valid_idx]]\n",
    "\n",
    "    test_files   = all_files[shuffled[valid_idx:test_idx+1]]\n",
    "    test_targets = all_targets[shuffled[valid_idx:test_idx+1]]\n",
    "\n",
    "    for i in range(len(valid_files)):\n",
    "        #print(valid_files[i][8:10],valid_targets[i])\n",
    "        if (\n",
    "                (valid_files[i][8:10]=='No') & (valid_targets[i][0]==0) |\n",
    "                (valid_files[i][8:11]=='Yes') & (valid_targets[i][0]==1)\n",
    "            ):\n",
    "            print(valid_files[i],valid_targets[i])\n",
    "\n",
    "    # pre-process the data for Keras\n",
    "    train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "    valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "    test_tensors = paths_to_tensor(test_files).astype('float32')/255\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_data('images\\Experiment_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check random training image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = train_tensors[np.random.choice(train_tensors)]\n",
    "print(img)\n",
    "plt.imgshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built and Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "batch_size = 150\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "### TODO: Define your architecture.\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(224, 224,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64*2, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64*2, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.find_faces.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "## Original fit call before using the ImageDataGenerator\n",
    "#model.fit(train_tensors, train_targets, \n",
    "#          validation_data=(valid_tensors, valid_targets),\n",
    "#          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=2)\n",
    "\n",
    "# this is the augmentation configuration I will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow(train_tensors, train_targets)\n",
    "validation_generator = train_datagen.flow(valid_tensors, valid_targets)\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator\n",
    "        , steps_per_epoch=2000 // batch_size\n",
    "        , epochs=epochs\n",
    "        , validation_data=validation_generator\n",
    "        , validation_steps=800 // batch_size\n",
    "        , callbacks=[checkpointer], verbose=2)\n",
    "\n",
    "model.load_weights('saved_models/weights.best.find_faces.hdf5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Accuracy Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "face_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(face_predictions)==np.argmax(test_targets, axis=1))/len(face_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
